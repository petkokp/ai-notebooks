{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self, phi_idx: int, device='cpu') -> None:\n",
    "        super().__init__()\n",
    "        self.phi_idx = phi_idx\n",
    "        self.device = device\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            probs: Tensor,\n",
    "            target: Tensor,\n",
    "            target_lengths: Tensor\n",
    "            ) -> Tensor:\n",
    "        target_lengths = target_lengths.to(self.device)\n",
    "        batch_size, max_length, *_ = probs.shape\n",
    "        n_chars = target_lengths.max().item()\n",
    "        n_nulls = max_length - n_chars\n",
    "        \n",
    "        scores = self.get_score_matrix(batch_size, n_chars, n_nulls)\n",
    "        scores = scores.to(self.device)\n",
    "\n",
    "        for c in range(n_chars + 1):\n",
    "            for p in range(n_nulls + 1):\n",
    "                if c == 0 and p == 0:\n",
    "                    continue\n",
    "                scores = self.update_scores(scores, probs, target, p, c)\n",
    "        return self.calc_loss(scores, target_lengths)\n",
    "\n",
    "    def calc_loss(self, scores: Tensor, target_lengths: Tensor) -> Tensor:\n",
    "        loss = torch.diagonal(torch.index_select(\n",
    "            scores[:, :, -1], dim=1, index=target_lengths\n",
    "            ))\n",
    "        loss = -1 * loss\n",
    "        return loss.mean()\n",
    "\n",
    "    def get_score_matrix(\n",
    "            self, batch_size: int, n_chars: int, n_nulls: int\n",
    "            ) -> Tensor:\n",
    "        return torch.zeros(batch_size, n_chars + 1, n_nulls + 1)\n",
    "\n",
    "    def update_scores(\n",
    "            self, scores: Tensor, probs: Tensor, target: Tensor, p: int, c: int\n",
    "            ) -> Tensor:\n",
    "        if p == 0:\n",
    "            chars_probs = self.get_chars_probs(probs, target, c, p)\n",
    "            scores[:, c, p] = chars_probs + scores[:, c - 1, p]\n",
    "            return scores\n",
    "        elif c == 0:\n",
    "            phi_probs = self.get_phi_probs(probs, c, p)\n",
    "            scores[:, c, p] = phi_probs + scores[:, c, p - 1]\n",
    "            return scores\n",
    "        chars_probs = self.get_chars_probs(probs, target, c, p)\n",
    "        phi_probs = self.get_phi_probs(probs, c, p)\n",
    "        scores[:, c, p] = torch.logsumexp(\n",
    "            torch.stack(\n",
    "                [scores[:, c, p - 1] + self.log(phi_probs),\n",
    "                scores[:, c - 1, p] + self.log(chars_probs)]\n",
    "            ), dim=0)\n",
    "        return scores\n",
    "\n",
    "    def get_phi_probs(self, probs: Tensor, c: int, p: int) -> Tensor:\n",
    "        return probs[:, c + p - 1, self.phi_idx]\n",
    "\n",
    "    def get_chars_probs(\n",
    "            self, probs: Tensor, target: Tensor, c: int, p: int\n",
    "            ) -> Tensor:\n",
    "        all_seqs = probs[:, p + c - 1]\n",
    "        result = torch.index_select(all_seqs, dim=-1, index=target[:, c - 1])\n",
    "        return torch.diagonal(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_formated_date() -> str:\n",
    "    t = datetime.now()\n",
    "    return f'{t.year}{t.month}{t.day}-{t.hour}{t.minute}{t.second}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from networks.model import Model\n",
    "from data.tokenizer import CharTokenizer, BaseTokenizer\n",
    "from torch.optim import Optimizer\n",
    "from data.data import AudioPipeline, DataLoader, TextPipeline\n",
    "from typing import Callable, Union\n",
    "from torch.nn import Module\n",
    "from functools import wraps\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "class Trainer:\n",
    "    __train_loss_key = 'train_loss'\n",
    "    __test_loss_key = 'test_loss'\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            criterion: Module,\n",
    "            optimizer: Optimizer,\n",
    "            model: Module,\n",
    "            device: str,\n",
    "            train_loader: DataLoader,\n",
    "            test_loader: DataLoader,\n",
    "            epochs: int,\n",
    "            length_multiplier: float\n",
    "    ) -> None:\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.step_history = dict()\n",
    "        self.history = dict()\n",
    "        self.length_multiplier = length_multiplier\n",
    "\n",
    "    def fit(self):\n",
    "        for _ in range(self.epochs):\n",
    "            self.train()\n",
    "            # self.test()\n",
    "            self.print_results()\n",
    "\n",
    "    def set_train_mode(self) -> None:\n",
    "        self.model = self.model.train()\n",
    "\n",
    "    def set_test_mode(self) -> None:\n",
    "        self.model = self.model.eval()\n",
    "\n",
    "    def print_results(self):\n",
    "        result = ''\n",
    "        for key, value in self.history.items():\n",
    "            result += f'{key}: {str(value[-1])}, '\n",
    "        print(result[:-2])\n",
    "\n",
    "    def test(self):\n",
    "        total_loss = 0\n",
    "        self.set_test_mode()\n",
    "        for x, y, lengths in self.test_loader:\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            max_len = int(x.shape[0] * self.length_multiplier)\n",
    "            x = torch.squeeze(x, dim=1)\n",
    "            result = self.model(x, max_len)\n",
    "            result = result.reshape(-1, result.shape[-1])\n",
    "            y = y.reshape(-1)\n",
    "            y = torch.squeeze(y)\n",
    "            loss = self.criterion(torch.squeeze(result), y)\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(self.test_loader)\n",
    "        if self.__test_loss_key in self.history:\n",
    "            self.history[self.__test_loss_key].append(total_loss)\n",
    "        else:\n",
    "            self.history[self.__test_loss_key] = [total_loss]\n",
    "\n",
    "    def train(self):\n",
    "        total_loss = 0\n",
    "        self.set_train_mode()\n",
    "        for (x, y, length) in self.train_loader:\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            max_len = int(x.shape[1] * self.length_multiplier)\n",
    "            x = torch.squeeze(x, dim=1)\n",
    "            self.optimizer.zero_grad()\n",
    "            probs, term_state = self.model(x, max_len)\n",
    "            loss = self.criterion(probs, y, length)\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(self.train_loader)\n",
    "        if self.__train_loss_key in self.history:\n",
    "            self.history[self.__train_loss_key].append(total_loss)\n",
    "        else:\n",
    "            self.history[self.__train_loss_key] = [total_loss]\n",
    "\n",
    "\n",
    "def get_model_args(\n",
    "        vocab_size: int,\n",
    "        pad_idx: int,\n",
    "        phi_idx: int,\n",
    "        sos_idx: int\n",
    ") -> dict:\n",
    "    prednet_params = {\n",
    "        'vocab_size': vocab_size,\n",
    "        'emb_dim': 128,\n",
    "        'pad_idx': pad_idx,\n",
    "        'hidden_size': 256,\n",
    "        'n_layers': 2,\n",
    "        'dropout': 0.2\n",
    "    }\n",
    "\n",
    "    transnet_params = {\n",
    "        'input_size': 512,\n",
    "        'hidden_size': 512,\n",
    "        'n_layers': 3,\n",
    "        'dropout': 0.3,\n",
    "        'is_bidirectional': True\n",
    "    }\n",
    "\n",
    "    joinnet_params = {\n",
    "        'input_size': 512,\n",
    "        'vocab_size': vocab_size,\n",
    "        'mode': 'multiplicative'\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'prednet_params': prednet_params,\n",
    "        'transnet_params': transnet_params,\n",
    "        'joinnet_params': joinnet_params,\n",
    "        'device': device,\n",
    "        'phi_idx': phi_idx,\n",
    "        'pad_idx': pad_idx,\n",
    "        'sos_idx': sos_idx\n",
    "    }\n",
    "\n",
    "\n",
    "def load_model(vocab_size: int, *args, **kwargs) -> Module:\n",
    "    return Model(**get_model_args(vocab_size, *args, **kwargs))\n",
    "\n",
    "\n",
    "def get_tokenizer():\n",
    "    tokenizer = CharTokenizer()\n",
    "    tokenizer = tokenizer.add_phi_token().add_pad_token()\n",
    "    tokenizer = tokenizer.add_sos_token().add_eos_token()\n",
    "    with open('vocab.txt', 'r') as f:\n",
    "        vocab = f.read().split('\\n')\n",
    "    tokenizer.set_tokenizer(vocab)\n",
    "    tokenizer.save_tokenizer('tokenizer.json')\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def get_data_loader(\n",
    "        file_path: Union[str, Path],\n",
    "        tokenizer: BaseTokenizer\n",
    "):\n",
    "    audio_pipeline = AudioPipeline()\n",
    "    text_pipeline = TextPipeline()\n",
    "    batch_size = 8\n",
    "    return DataLoader(\n",
    "        file_path,\n",
    "        text_pipeline,\n",
    "        audio_pipeline,\n",
    "        tokenizer,\n",
    "        batch_size\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "def get_trainer(batch_size, file_text, training_file_path, testing_file_path):\n",
    "    tokenizer = get_tokenizer()\n",
    "    phi_idx = tokenizer.special_tokens.phi_id\n",
    "    pad_idx = tokenizer.special_tokens.pad_id\n",
    "    sos_idx = tokenizer.special_tokens.sos_id\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    train_loader = get_data_loader(\n",
    "        training_file_path,\n",
    "        tokenizer\n",
    "    )\n",
    "    test_loader = get_data_loader(\n",
    "        testing_file_path,\n",
    "        tokenizer\n",
    "    )\n",
    "    criterion = Loss(phi_idx)\n",
    "    model = load_model(\n",
    "        vocab_size,\n",
    "        pad_idx=pad_idx,\n",
    "        phi_idx=phi_idx,\n",
    "        sos_idx=sos_idx\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        momentum=0.9\n",
    "    )\n",
    "    length_multiplier = 1.5\n",
    "    return Trainer(\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        model=model,\n",
    "        device=device,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=50,\n",
    "        length_multiplier=length_multiplier\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = get_trainer()\n",
    "trainer.fit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
