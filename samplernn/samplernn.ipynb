{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"SampleRNN: An Unconditional End-to-End Neural Audio Generation Model\" - paper implementation - https://arxiv.org/pdf/1612.07837.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from model.sample_rnn import SampleRNN\n",
    "from model.predictor import Predictor\n",
    "from optim.gradient_clipping import gradient_clipping\n",
    "from nn.sequence_nll_loss_bits import sequence_nll_loss_bits\n",
    "from trainer.trainer import Trainer\n",
    "from datasets.dataloader import DataLoader\n",
    "from datasets.folder_dataset import FolderDataset\n",
    "from natsort import natsorted\n",
    "from functools import reduce\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "default_params = {\n",
    "    'exp': 'TEST',\n",
    "    'n_rnn': 1,\n",
    "    'dim': 1024,\n",
    "    'learn_h0': True,\n",
    "    'q_levels': 256,\n",
    "    'seq_len': 1024,\n",
    "    'weight_norm': True,\n",
    "    'batch_size': 128,\n",
    "    'val_frac': 0.1,\n",
    "    'test_frac': 0.1,\n",
    "    'keep_old_checkpoints': False,\n",
    "    'datasets_path': 'datasets',\n",
    "    'results_path': 'results',\n",
    "    'epoch_limit': 1000,\n",
    "    'resume': True,\n",
    "    'sample_rate': 16000,\n",
    "    'n_samples': 1,\n",
    "    'sample_length': 80000,\n",
    "    'loss_smoothing': 0.99,\n",
    "    'cuda': False,\n",
    "    'frame_sizes': 16,\n",
    "    'dataset': 'example'\n",
    "    \n",
    "}\n",
    "\n",
    "tag_params = [\n",
    "    'exp', 'frame_sizes', 'n_rnn', 'dim', 'learn_h0', 'q_levels', 'seq_len',\n",
    "    'batch_size', 'dataset', 'val_frac', 'test_frac'\n",
    "]\n",
    "\n",
    "\n",
    "def param_to_string(value):\n",
    "    if isinstance(value, bool):\n",
    "        return 'T' if value else 'F'\n",
    "    elif isinstance(value, list):\n",
    "        return ','.join(map(param_to_string, value))\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def make_tag(params):\n",
    "    return '-'.join(\n",
    "        key + ':' + param_to_string(params[key])\n",
    "        for key in tag_params\n",
    "        if key not in default_params or params[key] != default_params[key]\n",
    "    )\n",
    "\n",
    "\n",
    "def setup_results_dir(params):\n",
    "    def ensure_dir_exists(path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    tag = make_tag(params)\n",
    "    results_path = os.path.abspath(params['results_path'])\n",
    "    ensure_dir_exists(results_path)\n",
    "    results_path = os.path.join(results_path, tag)\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    elif not params['resume']:\n",
    "        shutil.rmtree(results_path)\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    for subdir in ['checkpoints', 'samples']:\n",
    "        ensure_dir_exists(os.path.join(results_path, subdir))\n",
    "\n",
    "    return results_path\n",
    "\n",
    "\n",
    "def tee_stdout(log_path):\n",
    "    log_file = open(log_path, 'a', 1)\n",
    "    stdout = sys.stdout\n",
    "\n",
    "    class Tee:\n",
    "\n",
    "        def write(self, string):\n",
    "            log_file.write(string)\n",
    "            stdout.write(string)\n",
    "\n",
    "        def flush(self):\n",
    "            log_file.flush()\n",
    "            stdout.flush()\n",
    "\n",
    "    sys.stdout = Tee()\n",
    "\n",
    "\n",
    "def make_data_loader(overlap_len, params):\n",
    "    path = os.path.join(params['datasets_path'], params['dataset'])\n",
    "\n",
    "    def data_loader(split_from, split_to, eval):\n",
    "        dataset = FolderDataset(\n",
    "            path, overlap_len, params['q_levels'], split_from, split_to\n",
    "        )\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=params['batch_size'],\n",
    "            seq_len=params['seq_len'],\n",
    "            overlap_len=overlap_len,\n",
    "            shuffle=(not eval),\n",
    "            drop_last=(not eval)\n",
    "        )\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = default_params\n",
    "\n",
    "results_path = setup_results_dir(params)\n",
    "tee_stdout(os.path.join(results_path, 'log'))\n",
    "\n",
    "model = SampleRNN(\n",
    "    frame_sizes=params['frame_sizes'],\n",
    "    n_rnn=params['n_rnn'],\n",
    "    dim=params['dim'],\n",
    "    learn_h0=params['learn_h0'],\n",
    "    q_levels=params['q_levels'],\n",
    "    weight_norm=params['weight_norm']\n",
    ")\n",
    "predictor = Predictor(model)\n",
    "if params['cuda']:\n",
    "    model = model.cuda()\n",
    "    predictor = predictor.cuda()\n",
    "\n",
    "optimizer = gradient_clipping(torch.optim.Adam(predictor.parameters()))\n",
    "\n",
    "data_loader = make_data_loader(model.lookback, params)\n",
    "test_split = 1 - params['test_frac']\n",
    "val_split = test_split - params['val_frac']\n",
    "\n",
    "trainer = Trainer(\n",
    "    predictor, sequence_nll_loss_bits, optimizer,\n",
    "    data_loader(0, val_split, eval=False),\n",
    "    cuda=params['cuda']\n",
    ")\n",
    "\n",
    "trainer.run(params['epoch_limit'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
