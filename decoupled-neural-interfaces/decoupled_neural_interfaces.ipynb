{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Decoupled Neural Interfaces using Synthetic Gradients\" paper implementation - https://arxiv.org/pdf/1608.05343.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class mnist():\n",
    "    def __init__(self, args):\n",
    "        train_dataset = dsets.MNIST(root='./data',\n",
    "                                    train=True,\n",
    "                                    transform=transforms.ToTensor(),\n",
    "                                    download=True)\n",
    "\n",
    "        test_dataset = dsets.MNIST(root='./data',\n",
    "                                   train=False,\n",
    "                                   transform=transforms.ToTensor())\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=args.batch_size,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                       batch_size=args.batch_size,\n",
    "                                                       shuffle=False)\n",
    "        self.input_dims = 784\n",
    "        self.num_classes = 10\n",
    "        self.in_channel = 1\n",
    "        self.num_train = len(train_dataset)\n",
    "\n",
    "\n",
    "class cifar10():\n",
    "    def __init__(self, args):\n",
    "        transform = self.image_transform()\n",
    "        train_dataset = dsets.CIFAR10(root='./data/',\n",
    "                                      train=True,\n",
    "                                      transform=transform,\n",
    "                                      download=True)\n",
    "\n",
    "        test_dataset = dsets.CIFAR10(root='./data/',\n",
    "                                     train=False,\n",
    "                                     transform=transforms.ToTensor())\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                        batch_size=100,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "        self.test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                       batch_size=100,\n",
    "                                                       shuffle=False)\n",
    "        self.num_classes = 10\n",
    "        self.in_channel = 3\n",
    "        self.num_train = len(train_dataset)\n",
    "\n",
    "    def image_transform(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Scale(40),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(28),\n",
    "            transforms.ToTensor()])\n",
    "        return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class dni_linear(nn.Module):\n",
    "    def __init__(self, input_dims, num_classes, dni_hidden_size=1024, conditioned=False):\n",
    "        super(dni_linear, self).__init__()\n",
    "        self.conditioned = conditioned\n",
    "        if self.conditioned:\n",
    "            dni_input_dims = input_dims+num_classes\n",
    "        else:\n",
    "            dni_input_dims = input_dims\n",
    "        self.layer1 = nn.Sequential(\n",
    "                      nn.Linear(dni_input_dims, dni_hidden_size),\n",
    "                      nn.BatchNorm1d(dni_hidden_size),\n",
    "                      nn.ReLU()\n",
    "                      )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                      nn.Linear(dni_hidden_size, dni_hidden_size),\n",
    "                      nn.BatchNorm1d(dni_hidden_size),\n",
    "                      nn.ReLU()\n",
    "                      )\n",
    "        self.layer3 = nn.Linear(dni_hidden_size, input_dims)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if self.conditioned:\n",
    "            assert y is not None\n",
    "            x = torch.cat((x, y), 1)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "\n",
    "class dni_Conv2d(nn.Module):\n",
    "    def __init__(self, input_dims, input_size, num_classes, dni_hidden_size=64, conditioned=False):\n",
    "        super(dni_Conv2d, self).__init__()\n",
    "        self.conditioned = conditioned\n",
    "        if self.conditioned:\n",
    "            dni_input_dims = input_dims+1\n",
    "        else:\n",
    "            dni_input_dims = input_dims\n",
    "\n",
    "        self.input_size = list(input_size)\n",
    "        self.label_emb = nn.Linear(num_classes, np.prod(np.array(input_size)))\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "                      nn.Conv2d(dni_input_dims, dni_hidden_size, kernel_size=5, padding=2),\n",
    "                      nn.BatchNorm2d(dni_hidden_size),\n",
    "                      nn.ReLU())\n",
    "        self.layer2 = nn.Sequential( \n",
    "                      nn.Conv2d(dni_hidden_size, dni_hidden_size, kernel_size=5, padding=2),\n",
    "                      nn.BatchNorm2d(dni_hidden_size),\n",
    "                      nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "                      nn.Conv2d(dni_hidden_size, input_dims, kernel_size=5, padding=2))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if self.conditioned:\n",
    "            assert y is not None\n",
    "            y = self.label_emb(y)\n",
    "            y = y.view([-1, 1]+self.input_size)\n",
    "            x = torch.cat((x, y), 1)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self, in_channel, conditioned_DNI, num_classes):\n",
    "        super(cnn, self).__init__()\n",
    "\n",
    "               \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "\n",
    "        # DNI module\n",
    "        self._layer1 = dni_Conv2d(16, (14, 14), num_classes, conditioned=conditioned_DNI)\n",
    "        self._layer2 = dni_Conv2d(32, (7, 7), num_classes, conditioned=conditioned_DNI)\n",
    "        self._fc = dni_linear(num_classes, num_classes, conditioned=conditioned_DNI)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "                   self.layer1, \n",
    "                   self.layer2, \n",
    "                   self.fc)\n",
    "        self.dni = nn.Sequential(\n",
    "                   self._layer1, \n",
    "                   self._layer2, \n",
    "                   self._fc)\n",
    "        self.optimizers = []\n",
    "        self.forwards = []\n",
    "        self.init_optimzers()\n",
    "        self.init_forwards()\n",
    "\n",
    "    def init_optimzers(self, learning_rate=0.001):\n",
    "        self.optimizers.append(torch.optim.Adam(self.layer1.parameters(), lr=learning_rate))\n",
    "        self.optimizers.append(torch.optim.Adam(self.layer2.parameters(), lr=learning_rate))\n",
    "        self.optimizers.append(torch.optim.Adam(self.fc.parameters(), lr=learning_rate))\n",
    "        self.optimizer = torch.optim.Adam(self.cnn.parameters(), lr=learning_rate)\n",
    "        self.grad_optimizer = torch.optim.Adam(self.dni.parameters(), lr=learning_rate)\n",
    "\n",
    "    def init_forwards(self):\n",
    "        self.forwards.append(self.forward_layer1)\n",
    "        self.forwards.append(self.forward_layer2)\n",
    "        self.forwards.append(self.forward_fc)\n",
    "\n",
    "    def forward_layer1(self, x, y=None):\n",
    "        out = self.layer1(x)\n",
    "        grad = self._layer1(out, y)\n",
    "        return out, grad\n",
    " \n",
    "    def forward_layer2(self, x, y=None):\n",
    "        out = self.layer2(x)\n",
    "        grad = self._layer2(out, y)\n",
    "        return out, grad\n",
    "    \n",
    "    def forward_fc(self, x, y=None):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.fc(x)\n",
    "        grad = self._fc(out, y)\n",
    "        return out, grad\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        layer1 = self.layer1(x)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer2_flat = layer2.view(layer2.size(0), -1)\n",
    "        fc = self.fc(layer2_flat)\n",
    "        if y is not None:\n",
    "            grad_layer1 = self._layer1(layer1, y)\n",
    "            grad_layer2 = self._layer2(layer2, y)\n",
    "            grad_fc = self._fc(fc, y)\n",
    "            return (layer1, layer2, fc), (grad_layer1, grad_layer2, grad_fc)\n",
    "        else:\n",
    "            return layer1, layer2, fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
