{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"DRAW: A Recurrent Neural Network For Image Generation\" paper implementation - https://arxiv.org/pdf/1502.04623.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawModel(nn.Module):\n",
    "    def __init__(self,T,A,B,z_size,N,dec_size,enc_size):\n",
    "        super(DrawModel,self).__init__()\n",
    "        self.T = T\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.z_size = z_size\n",
    "        self.N = N\n",
    "        self.dec_size = dec_size\n",
    "        self.enc_size = enc_size\n",
    "\n",
    "        self.cs = [0] * T\n",
    "        self.logsigmas,self.sigmas,self.mus = [0] * T,[0] * T,[0] * T\n",
    "\n",
    "        self.encoder = nn.LSTMCell(2 * N * N + dec_size, enc_size)\n",
    "        self.encoder_gru = nn.GRUCell(2 * N * N + dec_size, enc_size)\n",
    "        self.mu_linear = nn.Linear(dec_size, z_size)\n",
    "        self.sigma_linear = nn.Linear(dec_size, z_size)\n",
    "\n",
    "        self.decoder = nn.LSTMCell(z_size,dec_size)\n",
    "        self.decoder_gru = nn.GRUCell(z_size,dec_size)\n",
    "        self.dec_linear = nn.Linear(dec_size,5)\n",
    "        self.dec_w_linear = nn.Linear(dec_size,N*N)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def unit_prefix(x, n=1):\n",
    "      for i in range(n): x = x.unsqueeze(0)\n",
    "      return x\n",
    "  \n",
    "    def align(self, x, y, start_dim=0):\n",
    "      xd, yd = x.dim(), y.dim()\n",
    "      if xd > yd: y = self.unit_prefix(y, xd - yd)\n",
    "      elif yd > xd: x = self.unit_prefix(x, yd - xd)\n",
    "\n",
    "      xs, ys = list(x.size()), list(y.size())\n",
    "      nd = len(ys)\n",
    "      for i in range(start_dim, nd):\n",
    "          td = nd-i-1\n",
    "          if   ys[td]==1: ys[td] = xs[td]\n",
    "          elif xs[td]==1: xs[td] = ys[td]\n",
    "      return x.expand(*xs), y.expand(*ys)\n",
    "\n",
    "\n",
    "    def normalSample(self):\n",
    "        return torch.randn(self.batch_size,self.z_size)\n",
    "\n",
    "    def compute_mu(self,g,rng,delta):\n",
    "        rng_t,delta_t = self.align(rng,delta)\n",
    "        tmp = (rng_t - self.N / 2 - 0.5) * delta_t\n",
    "        tmp_t,g_t = self.align(tmp,g)\n",
    "        mu = tmp_t + g_t\n",
    "        return mu\n",
    "\n",
    "    def filterbank(self,gx,gy,sigma2,delta):\n",
    "        rng = torch.arange(0,self.N).view(1,-1)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            rng = rng.cuda()\n",
    "        \n",
    "        mu_x = self.compute_mu(gx,rng,delta)\n",
    "        mu_y = self.compute_mu(gy,rng,delta)\n",
    "\n",
    "        a = torch.arange(0,self.A).view(1,1,-1)\n",
    "        b = torch.arange(0,self.B).view(1,1,-1)\n",
    "\n",
    "        mu_x = mu_x.view(-1,self.N,1)\n",
    "        mu_y = mu_y.view(-1,self.N,1)\n",
    "        sigma2 = sigma2.view(-1,1,1)\n",
    "        \n",
    "        Fx = self.filterbank_matrices(a,mu_x,sigma2)\n",
    "        Fy = self.filterbank_matrices(b,mu_y,sigma2)\n",
    "\n",
    "        return Fx,Fy\n",
    "    \n",
    "    def filterbank_matrices(self,a,mu_x,sigma2,epsilon=1e-9):\n",
    "        t_a,t_mu_x = self.align(a,mu_x)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            t_a = t_a.cuda()\n",
    "            t_mu_x = t_mu_x.cuda()\n",
    "        \n",
    "        temp = t_a - t_mu_x\n",
    "        temp,t_sigma = self.align(temp,sigma2)\n",
    "        temp = temp / (t_sigma * 2)\n",
    "        F = torch.exp(-torch.pow(temp,2))\n",
    "        F = F / (F.sum(2,True).expand_as(F) + epsilon)\n",
    "        return F\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.batch_size = x.size()[0]\n",
    "        h_dec_prev = torch.zeros(self.batch_size,self.dec_size)\n",
    "        h_enc_prev = torch.zeros(self.batch_size, self.enc_size)\n",
    "\n",
    "        enc_state = torch.zeros(self.batch_size,self.enc_size)\n",
    "        dec_state = torch.zeros(self.batch_size, self.dec_size)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            h_dec_prev = h_dec_prev.cuda()\n",
    "            h_enc_prev = h_enc_prev.cuda()\n",
    "            enc_state = enc_state.cuda()\n",
    "            dec_state = dec_state.cuda()\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            c_prev = torch.zeros(self.batch_size,self.A * self.B) if t == 0 else self.cs[t-1]\n",
    "            \n",
    "            if USE_CUDA:\n",
    "                c_prev = c_prev.cuda()\n",
    "            \n",
    "            x_hat = x - self.sigmoid(c_prev)\n",
    "            r_t = self.read(x,x_hat,h_dec_prev)\n",
    "            h_enc_prev, enc_state = self.encoder(torch.cat((r_t,h_dec_prev),1), (h_enc_prev,enc_state))\n",
    "            z, self.mus[t], self.logsigmas[t], self.sigmas[t] = self.sampleQ(h_enc_prev)\n",
    "            h_dec,dec_state = self.decoder(z, (h_dec_prev, dec_state))\n",
    "            self.cs[t] = c_prev + self.write(h_dec)\n",
    "            h_dec_prev = h_dec\n",
    "\n",
    "    def loss(self,x):\n",
    "        self.forward(x)\n",
    "        criterion = nn.BCELoss()\n",
    "        x_recons = self.sigmoid(self.cs[-1])\n",
    "        Lx = criterion(x_recons,x) * self.A * self.B\n",
    "        Lz = 0\n",
    "        kl_terms = [0] * self.T\n",
    "        for t in range(self.T):\n",
    "            mu_2 = self.mus[t] * self.mus[t]\n",
    "            sigma_2 = self.sigmas[t] * self.sigmas[t]\n",
    "            logsigma = self.logsigmas[t]\n",
    "            kl_terms[t] = 0.5 * torch.sum(mu_2+sigma_2-2 * logsigma,1) - self.T * 0.5\n",
    "            Lz += kl_terms[t]\n",
    "        Lz = torch.mean(Lz)\n",
    "        loss = Lz + Lx\n",
    "        return loss\n",
    "\n",
    "    def attn_window(self,h_dec):\n",
    "        params = self.dec_linear(h_dec)\n",
    "        gx_,gy_,log_sigma_2,log_delta,log_gamma = params.split(1,1)\n",
    "\n",
    "        gx = (self.A + 1) / 2 * (gx_ + 1)\n",
    "        gy = (self.B + 1) / 2 * (gy_ + 1)\n",
    "        delta = (max(self.A,self.B) - 1) / (self.N - 1) * torch.exp(log_delta)\n",
    "        sigma2 = torch.exp(log_sigma_2)\n",
    "        gamma = torch.exp(log_gamma)\n",
    "        return self.filterbank(gx,gy,sigma2,delta),gamma\n",
    "\n",
    "    def read(self,x,x_hat,h_dec_prev):\n",
    "        (Fx,Fy),gamma = self.attn_window(h_dec_prev)\n",
    "        \n",
    "        def filter_img(img,Fx,Fy,gamma,A,B,N):\n",
    "            Fxt = Fx.transpose(2,1)\n",
    "            img = img.view(-1,B,A)\n",
    "            glimpse = Fy.bmm(img.bmm(Fxt))\n",
    "            glimpse = glimpse.view(-1,N*N)\n",
    "            return glimpse * gamma.view(-1,1).expand_as(glimpse)\n",
    "        \n",
    "        x = filter_img(x,Fx,Fy,gamma,self.A,self.B,self.N)\n",
    "        x_hat = filter_img(x_hat,Fx,Fy,gamma,self.A,self.B,self.N)\n",
    "        return torch.cat((x,x_hat),1)\n",
    "\n",
    "    def write(self,h_dec=0):\n",
    "        w = self.dec_w_linear(h_dec)\n",
    "        w = w.view(self.batch_size,self.N,self.N)\n",
    "        (Fx,Fy),gamma = self.attn_window(h_dec)\n",
    "        Fyt = Fy.transpose(2,1)\n",
    "        wr = Fyt.bmm(w.bmm(Fx))\n",
    "        wr = wr.view(self.batch_size,self.A*self.B)\n",
    "        return wr / gamma.view(-1,1).expand_as(wr)\n",
    "\n",
    "    def sampleQ(self,h_enc):\n",
    "        e = self.normalSample()\n",
    "        mu = self.mu_linear(h_enc)\n",
    "        log_sigma = self.sigma_linear(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            e = e.cuda()\n",
    "            sigma = sigma.cuda()\n",
    "        return mu + sigma * e , mu , log_sigma, sigma\n",
    "\n",
    "    def generate(self, batch_size = 64):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h_dec_prev = torch.zeros(self.batch_size,self.dec_size)\n",
    "            dec_state = torch.zeros(self.batch_size, self.dec_size)\n",
    "            \n",
    "            if USE_CUDA:\n",
    "                h_dec_prev = h_dec_prev.cuda()\n",
    "                dec_state = dec_state.cuda()\n",
    "            \n",
    "            for t in range(self.T):\n",
    "                c_prev = torch.zeros(self.batch_size, self.A * self.B) if t == 0 else self.cs[t - 1]\n",
    "                z = self.normalSample()\n",
    "                \n",
    "                if USE_CUDA:\n",
    "                    c_prev = c_prev.cuda()\n",
    "                    z = z.cuda()\n",
    "                \n",
    "                h_dec, dec_state = self.decoder(z, (h_dec_prev, dec_state))\n",
    "                self.cs[t] = c_prev + self.write(h_dec)\n",
    "                h_dec_prev = h_dec\n",
    "            imgs = []\n",
    "            \n",
    "            for img in self.cs:\n",
    "                imgs.append(self.sigmoid(img).cpu().data.numpy())\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "T = 10\n",
    "batch_size = 64\n",
    "A = 28\n",
    "B = 28\n",
    "z_size = 10\n",
    "N = 5\n",
    "dec_size = 256\n",
    "enc_size = 256\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "clip = 5.0\n",
    "\n",
    "result_dir = './results/'\n",
    "model_dir = './models/'\n",
    "\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MNIST('./data',\n",
    "          train=True,\n",
    "          download=True,\n",
    "          transform=transforms.Compose([\n",
    "              transforms.ToTensor()])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def save_image(x,count=0, dir_name='', batch_size=64):\n",
    "    for t in range(T):\n",
    "        img = xrecons_grid(x[t],B,A)\n",
    "        plt.matshow(img, cmap=plt.cm.gray)\n",
    "        imgname = dir_name + '/count_%d_%s_%d.png' % (count, 'test', t)\n",
    "        plt.savefig(imgname)\n",
    "\n",
    "def xrecons_grid(X,B=28,A=28):\n",
    "    padsize=1\n",
    "    padval=.5\n",
    "    ph=B+2*padsize\n",
    "    pw=A+2*padsize\n",
    "    batch_size=X.shape[0]\n",
    "    N=int(np.sqrt(batch_size))\n",
    "    X=X.reshape((N,N,B,A))\n",
    "    img=np.ones((N*ph,N*pw))*padval\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            startr=i*ph+padsize\n",
    "            endr=startr+B\n",
    "            startc=j*pw+padsize\n",
    "            endc=startc+A\n",
    "            img[startr:endr,startc:endc]=X[i,j,:,:]\n",
    "    return img\n",
    "\n",
    "def generate_image(model, count):\n",
    "    x = model.generate(batch_size)\n",
    "    save_image(x, count, result_dir)\n",
    "\n",
    "def save_example_image():\n",
    "    train_iter = iter(train_loader)\n",
    "    data, _ = next(train_iter)\n",
    "    img = data.cpu().numpy().reshape(batch_size, 28, 28)\n",
    "    imgs = xrecons_grid(img, B, A)\n",
    "    plt.matshow(imgs, cmap=plt.cm.gray)\n",
    "    plt.savefig(result_dir + '/example.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model not restored\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = DrawModel(T, A, B, z_size, N, dec_size, enc_size)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_dir + '/draw.pkl'))\n",
    "    print(\"\\nModel restored\\n\")\n",
    "except:\n",
    "    print(\"\\nModel not restored\\n\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m train_hist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m \u001b[43msave_example_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m, in \u001b[0;36msave_example_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_example_image\u001b[39m():\n\u001b[1;32m     35\u001b[0m     train_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[0;32m---> 36\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[1;32m     37\u001b[0m     img \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m     38\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m xrecons_grid(img, B, A)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_hist = {}\n",
    "train_hist['loss'] = []\n",
    "train_hist['per_epoch_time'] = []\n",
    "train_hist['total_time'] = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "save_example_image()\n",
    "\n",
    "avg_loss = 0\n",
    "count = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    for i, (data, _) in enumerate(train_loader):\n",
    "        if i == train_loader.dataset.__len__() // batch_size:\n",
    "            break\n",
    "\n",
    "        batch_size = data.size()[0]\n",
    "        data = data.view(batch_size, -1)\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            data = data.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        loss = model.loss(data)\n",
    "        train_hist['loss'].append(loss.item())\n",
    "        \n",
    "        avg_loss += loss.cpu().data.numpy()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "            \n",
    "        train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [%d/%d], Step[%d/%d], loss: %.4f'\n",
    "                  %(epoch, num_epochs, (i + 1), train_loader.dataset.__len__() // batch_size, avg_loss / 100))\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            if count % 3000 == 0:\n",
    "                torch.save(model.state_dict(), model_dir + '/draw_%d.pkl'%(count))\n",
    "                generate_image(model, count)\n",
    "            avg_loss = 0\n",
    "            \n",
    "torch.save(model.state_dict(), model_dir + '/draw.pkl')\n",
    "\n",
    "train_hist['total_time'].append(time.time() - start_time)\n",
    "print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(train_hist['per_epoch_time']), num_epochs, train_hist['total_time'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
