{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Net2Net: ACCELERATING LEARNING VIA KNOWLEDGE TRANSFER\" paper implementation - https://arxiv.org/pdf/1511.05641.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def net_to_wider_net(m1, m2, new_width, bnorm=None, out_size=None, noise=True,\n",
    "          random_init=True, weight_norm=True):\n",
    "    w1 = m1.weight.data\n",
    "    w2 = m2.weight.data\n",
    "    b1 = m1.bias.data\n",
    "\n",
    "    if \"Conv\" in m1.__class__.__name__ or \"Linear\" in m1.__class__.__name__:\n",
    "        if \"Conv\" in m1.__class__.__name__ and \"Linear\" in m2.__class__.__name__:\n",
    "            assert w2.size(1) % w1.size(\n",
    "                0) == 0, \"Linear units need to be multiple\"\n",
    "            if w1.dim() == 4:\n",
    "                factor = int(np.sqrt(w2.size(1) // w1.size(0)))\n",
    "                w2 = w2.view(w2.size(0), w2.size(1)//factor**2, factor, factor)\n",
    "            elif w1.dim() == 5:\n",
    "                assert out_size is not None, \"For conv3d -> linear out_size is necessary\"\n",
    "                factor = out_size[0] * out_size[1] * out_size[2]\n",
    "                w2 = w2.view(w2.size(0), w2.size(1)//factor, out_size[0],\n",
    "                             out_size[1], out_size[2])\n",
    "        else:\n",
    "            assert w1.size(0) == w2.size(\n",
    "                1), \"Module weights are not compatible\"\n",
    "        assert new_width > w1.size(0), \"New size should be larger\"\n",
    "\n",
    "        old_width = w1.size(0)\n",
    "        nw1 = m1.weight.data.clone()\n",
    "        nw2 = w2.clone()\n",
    "\n",
    "        if nw1.dim() == 4:\n",
    "            nw1.resize_(new_width, nw1.size(1), nw1.size(2), nw1.size(3))\n",
    "            nw2.resize_(nw2.size(0), new_width, nw2.size(2), nw2.size(3))\n",
    "        elif nw1.dim() == 5:\n",
    "            nw1.resize_(new_width, nw1.size(1), nw1.size(2),\n",
    "                        nw1.size(3), nw1.size(4))\n",
    "            nw2.resize_(nw2.size(0), new_width, nw2.size(2),\n",
    "                        nw2.size(3), nw2.size(4))\n",
    "        else:\n",
    "            nw1.resize_(new_width, nw1.size(1))\n",
    "            nw2.resize_(nw2.size(0), new_width)\n",
    "\n",
    "        if b1 is not None:\n",
    "            nb1 = m1.bias.data.clone()\n",
    "            nb1.resize_(new_width)\n",
    "\n",
    "        if bnorm is not None:\n",
    "            nrunning_mean = bnorm.running_mean.clone().resize_(new_width)\n",
    "            nrunning_var = bnorm.running_var.clone().resize_(new_width)\n",
    "            if bnorm.affine:\n",
    "                nweight = bnorm.weight.data.clone().resize_(new_width)\n",
    "                nbias = bnorm.bias.data.clone().resize_(new_width)\n",
    "\n",
    "        w2 = w2.transpose(0, 1)\n",
    "        nw2 = nw2.transpose(0, 1)\n",
    "\n",
    "        nw1.narrow(0, 0, old_width).copy_(w1)\n",
    "        nw2.narrow(0, 0, old_width).copy_(w2)\n",
    "        nb1.narrow(0, 0, old_width).copy_(b1)\n",
    "\n",
    "        if bnorm is not None:\n",
    "            nrunning_var.narrow(0, 0, old_width).copy_(bnorm.running_var)\n",
    "            nrunning_mean.narrow(0, 0, old_width).copy_(bnorm.running_mean)\n",
    "            if bnorm.affine:\n",
    "                nweight.narrow(0, 0, old_width).copy_(bnorm.weight.data)\n",
    "                nbias.narrow(0, 0, old_width).copy_(bnorm.bias.data)\n",
    "\n",
    "        if weight_norm:\n",
    "            for i in range(old_width):\n",
    "                norm = w1.select(0, i).norm()\n",
    "                w1.select(0, i).div_(norm)\n",
    "\n",
    "        tracking = dict()\n",
    "        for i in range(old_width, new_width):\n",
    "            idx = np.random.randint(0, old_width)\n",
    "            try:\n",
    "                tracking[idx].append(i)\n",
    "            except:\n",
    "                tracking[idx] = [idx]\n",
    "                tracking[idx].append(i)\n",
    "\n",
    "            if random_init:\n",
    "                n = m1.kernel_size[0] * m1.kernel_size[1] * m1.out_channels\n",
    "                if m2.weight.dim() == 4:\n",
    "                    n2 = m2.kernel_size[0] * \\\n",
    "                        m2.kernel_size[1] * m2.out_channels\n",
    "                elif m2.weight.dim() == 5:\n",
    "                    n2 = m2.kernel_size[0] * m2.kernel_size[1] * \\\n",
    "                        m2.kernel_size[2] * m2.out_channels\n",
    "                elif m2.weight.dim() == 2:\n",
    "                    n2 = m2.out_features * m2.in_features\n",
    "                nw1.select(0, i).normal_(0, np.sqrt(2./n))\n",
    "                nw2.select(0, i).normal_(0, np.sqrt(2./n2))\n",
    "            else:\n",
    "                nw1.select(0, i).copy_(w1.select(0, idx).clone())\n",
    "                nw2.select(0, i).copy_(w2.select(0, idx).clone())\n",
    "            nb1[i] = b1[idx]\n",
    "\n",
    "        if bnorm is not None:\n",
    "            nrunning_mean[i] = bnorm.running_mean[idx]\n",
    "            nrunning_var[i] = bnorm.running_var[idx]\n",
    "            if bnorm.affine:\n",
    "                nweight[i] = bnorm.weight.data[idx]\n",
    "                nbias[i] = bnorm.bias.data[idx]\n",
    "            bnorm.num_features = new_width\n",
    "\n",
    "        if not random_init:\n",
    "            for idx, d in tracking.items():\n",
    "                for item in d:\n",
    "                    nw2[item].div_(len(d))\n",
    "\n",
    "        w2.transpose_(0, 1)\n",
    "        nw2.transpose_(0, 1)\n",
    "\n",
    "        m1.out_channels = new_width\n",
    "        m2.in_channels = new_width\n",
    "\n",
    "        if noise:\n",
    "            noise = np.random.normal(scale=5e-2 * nw1.std(),\n",
    "                                     size=list(nw1.size()))\n",
    "            nw1 += th.FloatTensor(noise).type_as(nw1)\n",
    "\n",
    "        m1.weight.data = nw1\n",
    "\n",
    "        if \"Conv\" in m1.__class__.__name__ and \"Linear\" in m2.__class__.__name__:\n",
    "            if w1.dim() == 4:\n",
    "                m2.weight.data = nw2.view(\n",
    "                    m2.weight.size(0), new_width*factor**2)\n",
    "                m2.in_features = new_width*factor**2\n",
    "            elif w2.dim() == 5:\n",
    "                m2.weight.data = nw2.view(m2.weight.size(0), new_width*factor)\n",
    "                m2.in_features = new_width*factor\n",
    "        else:\n",
    "            m2.weight.data = nw2\n",
    "\n",
    "        m1.bias.data = nb1\n",
    "\n",
    "        if bnorm is not None:\n",
    "            bnorm.running_var = nrunning_var\n",
    "            bnorm.running_mean = nrunning_mean\n",
    "            if bnorm.affine:\n",
    "                bnorm.weight.data = nweight\n",
    "                bnorm.bias.data = nbias\n",
    "\n",
    "        return m1, m2, bnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
