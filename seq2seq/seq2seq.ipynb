{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sequence to Sequence Learning with Neural Networks\" paper implementation - https://arxiv.org/pdf/1409.3215.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from data_loader import Dataset\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11793 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3117\n",
      "eng 3117\n",
      "['you re disobeying orders ', 'you re disobeying orders ']\n",
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11793 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3117\n",
      "eng 3117\n",
      "['he s an aristocrat ', 'he s an aristocrat ']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 1 \n",
    "EOS_token = 2 \n",
    "\n",
    "args = {\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'gamma': 0.1,\n",
    "    'epochs_per_lr_drop': 450,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 8,\n",
    "    'num_epoch': 600,\n",
    "    'cuda': True,\n",
    "    'save_folder': os.path.expanduser('~/weights'),\n",
    "    'epochs_per_save': 10,\n",
    "    'batch_per_log': 10,\n",
    "    'auto_encoder': True,\n",
    "    'MAX_LENGTH': 10,\n",
    "    'bidirectional': False,\n",
    "    'hidden_size_decoder': 256,\n",
    "    'num_layer_decoder': 1,\n",
    "    'hidden_size_encoder': 256,\n",
    "    'num_layer_encoder': 1,\n",
    "    'teacher_forcing': False\n",
    "}\n",
    "\n",
    "if args['cuda']:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "trainset = Dataset(phase='train', max_input_length=10, auto_encoder=args['auto_encoder'])\n",
    "\n",
    "input_lang, output_lang = trainset.langs()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args['batch_size'],\n",
    "                                          shuffle=True, num_workers=args['num_workers'], pin_memory=False, drop_last=True)\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "testset = Dataset(phase='test', max_input_length=10, auto_encoder=args['auto_encoder'])\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1, pin_memory=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
