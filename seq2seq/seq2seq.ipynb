{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sequence to Sequence Learning with Neural Networks\" paper implementation - https://arxiv.org/pdf/1409.3215.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from data_loader import Dataset\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11793 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3117\n",
      "eng 3117\n",
      "['you re disobeying orders ', 'you re disobeying orders ']\n",
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11793 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3117\n",
      "eng 3117\n",
      "['he s an aristocrat ', 'he s an aristocrat ']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 1 \n",
    "EOS_token = 2 \n",
    "\n",
    "args = {\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'gamma': 0.1,\n",
    "    'epochs_per_lr_drop': 450,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 8,\n",
    "    'num_epoch': 600,\n",
    "    'cuda': True,\n",
    "    'save_folder': os.path.expanduser('~/weights'),\n",
    "    'epochs_per_save': 10,\n",
    "    'batch_per_log': 10,\n",
    "    'auto_encoder': True,\n",
    "    'MAX_LENGTH': 10,\n",
    "    'bidirectional': False,\n",
    "    'hidden_size_decoder': 256,\n",
    "    'num_layer_decoder': 1,\n",
    "    'hidden_size_encoder': 256,\n",
    "    'num_layer_encoder': 1,\n",
    "    'teacher_forcing': False\n",
    "}\n",
    "\n",
    "if args['cuda']:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "trainset = Dataset(phase='train', max_input_length=10, auto_encoder=args['auto_encoder'])\n",
    "\n",
    "input_lang, output_lang = trainset.langs()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args['batch_size'],\n",
    "                                          shuffle=True, num_workers=args['num_workers'], pin_memory=False, drop_last=True)\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "testset = Dataset(phase='test', max_input_length=10, auto_encoder=args['auto_encoder'])\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1, pin_memory=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size, batch_size, num_layers=1, bidirectional=False):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim=hidden_size)\n",
    "\n",
    "        if args['bidirectional']:\n",
    "            self.lstm_forward = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "            self.lstm_backward = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        if args['bidirectional']:\n",
    "            input_forward, input_backward = input\n",
    "            hidden_forward, hidden_backward = hidden\n",
    "            input_forward = self.embedding(input_forward).view(1, 1, -1)\n",
    "            input_backward = self.embedding(input_backward).view(1, 1, -1)\n",
    "\n",
    "            out_forward, (h_n_forward, c_n_forward) = self.lstm_forward(input_forward, hidden_forward)\n",
    "            out_backward, (h_n_backward, c_n_backward) = self.lstm_backward(input_backward, hidden_backward)\n",
    "\n",
    "            forward_state = (h_n_forward, c_n_forward)\n",
    "            backward_state = (h_n_backward, c_n_backward)\n",
    "            output_state = (forward_state, backward_state)\n",
    "\n",
    "            return output_state\n",
    "        else:\n",
    "            embedded = self.embedding(input).view(1, 1, -1)\n",
    "            rnn_input = embedded\n",
    "            output, (h_n, c_n) = self.lstm(rnn_input, hidden)\n",
    "            return output, (h_n, c_n)\n",
    "\n",
    "    def init_hidden(self):\n",
    "\n",
    "        if self.bidirectional:\n",
    "            encoder_state = [torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
    "                                      torch.zeros(self.num_layers, 1, self.hidden_size, device=device)]\n",
    "            encoder_state = {\"forward\": encoder_state, \"backward\": encoder_state}\n",
    "            return encoder_state\n",
    "        else:\n",
    "            encoder_state = [torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
    "                              torch.zeros(self.num_layers, 1, self.hidden_size, device=device)]\n",
    "            return encoder_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, batch_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size,\n",
    "                            hidden_size=hidden_size, num_layers=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output, (h_n, c_n) = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, (h_n, c_n)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return [torch.zeros(self.num_layers, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(self.num_layers, 1, self.hidden_size, device=device)]\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, bidirectional, hidden_size_encoder, hidden_size_decoder):\n",
    "        super(Linear, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        num_directions = int(bidirectional) + 1\n",
    "        self.linear_connection_op = nn.Linear(\n",
    "            num_directions * hidden_size_encoder, hidden_size_decoder)\n",
    "        self.connection_possibility_status = num_directions * \\\n",
    "            hidden_size_encoder == hidden_size_decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        if self.connection_possibility_status:\n",
    "            return input\n",
    "        else:\n",
    "            return self.linear_connection_op(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from transformations import reformat_tensor_mask\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, mask_input, mask_target, encoder, decoder, bridge, encoder_optimizer, decoder_optimizer, bridge_optimizer, criterion, max_length=args['MAX_LENGTH']):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    bridge_optimizer.zero_grad()\n",
    "\n",
    "    encoder_hiddens_last = []\n",
    "    loss = 0\n",
    "    for step_idx in range(args['batch_size']):\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "        input_tensor_step = input_tensor[:,\n",
    "                                         step_idx][input_tensor[:, step_idx] != 0]\n",
    "        input_length = input_tensor_step.size(0)\n",
    "\n",
    "        if args['bidirectional']:\n",
    "            encoder_outputs = torch.zeros(\n",
    "                args['batch_size'], max_length, 2 * encoder.hidden_size, device=device)\n",
    "            encoder_hidden_forward = encoder_hidden['forward']\n",
    "            encoder_hidden_backward = encoder_hidden['backward']\n",
    "            for ei in range(input_length):\n",
    "                (encoder_hidden_forward, encoder_hidden_backward) = encoder(\n",
    "                    (input_tensor_step[ei], input_tensor_step[input_length - 1 - ei]), (encoder_hidden_forward, encoder_hidden_backward))\n",
    "\n",
    "            hn_forward, cn_forward = encoder_hidden_forward\n",
    "            hn_backward, cn_backward = encoder_hidden_backward\n",
    "\n",
    "            encoder_hn = torch.cat((hn_forward, hn_backward), 2)\n",
    "            encoder_cn = torch.cat((cn_forward, cn_backward), 2)\n",
    "            encoder_hn_last_layer = encoder_hn[-1].view(1, 1, -1)\n",
    "            encoder_cn_last_layer = encoder_cn[-1].view(1, 1, -1)\n",
    "\n",
    "            encoder_hidden = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        else:\n",
    "            encoder_outputs = torch.zeros(\n",
    "                args['batch_size'], max_length, encoder.hidden_size, device=device)\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(\n",
    "                    input_tensor_step[ei], encoder_hidden)\n",
    "                encoder_outputs[step_idx, ei, :] = encoder_output[0, 0]\n",
    "\n",
    "            hn, cn = encoder_hidden\n",
    "            encoder_hn_last_layer = hn[-1].view(1, 1, -1)\n",
    "            encoder_cn_last_layer = cn[-1].view(1, 1, -1)\n",
    "            encoder_hidden = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        encoder_hidden = [bridge(item) for item in encoder_hidden]\n",
    "        encoder_hiddens_last.append(encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([SOS_token], device=device)\n",
    "    decoder_hiddens = encoder_hiddens_last\n",
    "\n",
    "    if args['teacher_forcing']:\n",
    "\n",
    "        for step_idx in range(args['batch_size']):\n",
    "            target_tensor_step = target_tensor[:,\n",
    "                                               step_idx][target_tensor[:, step_idx] != 0]\n",
    "            target_length = target_tensor_step.size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "\n",
    "                loss += criterion(decoder_output,\n",
    "                                  target_tensor_step[di].view(1))\n",
    "                decoder_input = target_tensor_step[di]\n",
    "\n",
    "        loss = loss / args['batch_size']\n",
    "\n",
    "    else:\n",
    "        for step_idx in range(args['batch_size']):\n",
    "\n",
    "            target_tensor_step = target_tensor[:,\n",
    "                                               step_idx][target_tensor[:, step_idx] != 0]\n",
    "            target_length = target_tensor_step.size(0)\n",
    "            decoder_hidden = decoder_hiddens[step_idx]\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                loss += criterion(decoder_output,\n",
    "                                  target_tensor_step[di].view(1))\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "        loss = loss / args['batch_size']\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_iters(encoder, decoder, bridge, print_every=1000, plot_every=100, learning_rate=0.1):\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    bridge_optimizer = optim.SGD(bridge.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    n_iters_per_epoch = int(len(trainset) / args['batch_size'])\n",
    "    for i in range(args['num_epochs']):\n",
    "\n",
    "        for iteration, data in enumerate(trainloader, 1):\n",
    "\n",
    "            training_pair = data\n",
    "\n",
    "            input_tensor = training_pair['sentence'][:, :, 0, :]\n",
    "            input_tensor, mask_input = reformat_tensor_mask(input_tensor)\n",
    "\n",
    "            target_tensor = training_pair['sentence'][:, :, 1, :]\n",
    "            target_tensor, mask_target = reformat_tensor_mask(target_tensor)\n",
    "\n",
    "            if device == torch.device(\"cuda\"):\n",
    "                input_tensor = input_tensor.cuda()\n",
    "                target_tensor = target_tensor.cuda()\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, mask_input, mask_target, encoder,\n",
    "                         decoder, bridge, encoder_optimizer, decoder_optimizer, bridge_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iteration % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (time_since(start, iteration / n_iters_per_epoch),\n",
    "                                             iteration, iteration / n_iters_per_epoch * 100, print_loss_avg))\n",
    "\n",
    "            if iteration % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "        print('####### Finished epoch %d of %d ########' %\n",
    "              (i+1, args['num_epochs']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 7s (- 3m 33s) (10 3%) 5.9281\n",
      "0m 14s (- 3m 20s) (20 6%) 5.1554\n",
      "0m 21s (- 3m 9s) (30 10%) 3.4639\n",
      "0m 34s (- 3m 39s) (40 13%) 3.7949\n",
      "0m 46s (- 3m 46s) (50 17%) 3.7609\n",
      "0m 56s (- 3m 39s) (60 20%) 3.3689\n",
      "1m 4s (- 3m 27s) (70 23%) 3.8071\n",
      "1m 13s (- 3m 15s) (80 27%) 3.9820\n",
      "1m 20s (- 3m 2s) (90 30%) 3.4321\n",
      "1m 27s (- 2m 49s) (100 34%) 3.4039\n",
      "1m 34s (- 2m 38s) (110 37%) 3.8280\n",
      "1m 41s (- 2m 27s) (120 40%) 3.4719\n",
      "1m 49s (- 2m 17s) (130 44%) 3.0237\n",
      "1m 56s (- 2m 7s) (140 47%) 3.4051\n",
      "2m 2s (- 1m 57s) (150 51%) 3.2150\n",
      "2m 9s (- 1m 48s) (160 54%) 3.6497\n",
      "2m 17s (- 1m 40s) (170 57%) 3.2089\n",
      "2m 24s (- 1m 31s) (180 61%) 3.4956\n",
      "2m 30s (- 1m 22s) (190 64%) 2.8890\n",
      "2m 38s (- 1m 14s) (200 68%) 3.1881\n",
      "2m 47s (- 1m 7s) (210 71%) 3.2242\n",
      "2m 55s (- 0m 59s) (220 74%) 3.3413\n",
      "3m 2s (- 0m 50s) (230 78%) 3.0550\n",
      "3m 14s (- 0m 43s) (240 81%) 3.3743\n",
      "3m 23s (- 0m 35s) (250 85%) 3.0892\n",
      "3m 31s (- 0m 27s) (260 88%) 3.3803\n",
      "3m 40s (- 0m 19s) (270 91%) 2.9289\n",
      "3m 47s (- 0m 11s) (280 95%) 2.6650\n",
      "3m 55s (- 0m 3s) (290 98%) 3.0407\n",
      "####### Finished epoch 1 of 10 ########\n",
      "4m 5s (- 116m 18s) (10 3%) 4.7913\n",
      "4m 13s (- 57m 47s) (20 6%) 2.9128\n",
      "4m 21s (- 38m 18s) (30 10%) 3.3923\n",
      "4m 27s (- 28m 20s) (40 13%) 3.1242\n",
      "4m 34s (- 22m 20s) (50 17%) 3.1386\n",
      "4m 41s (- 18m 17s) (60 20%) 3.5565\n",
      "4m 48s (- 15m 22s) (70 23%) 3.0609\n",
      "4m 54s (- 13m 8s) (80 27%) 3.3301\n",
      "5m 1s (- 11m 22s) (90 30%) 3.1835\n",
      "5m 7s (- 9m 57s) (100 34%) 3.0706\n",
      "5m 14s (- 8m 45s) (110 37%) 2.8272\n",
      "5m 21s (- 7m 45s) (120 40%) 2.9256\n",
      "5m 27s (- 6m 53s) (130 44%) 3.0314\n",
      "5m 34s (- 6m 8s) (140 47%) 3.3457\n",
      "5m 41s (- 5m 27s) (150 51%) 2.8148\n",
      "5m 48s (- 4m 52s) (160 54%) 3.0491\n",
      "6m 2s (- 4m 24s) (170 57%) 2.8775\n",
      "6m 13s (- 3m 56s) (180 61%) 2.9546\n",
      "6m 21s (- 3m 28s) (190 64%) 3.2971\n",
      "6m 29s (- 3m 3s) (200 68%) 3.0733\n",
      "6m 37s (- 2m 38s) (210 71%) 2.6723\n",
      "6m 44s (- 2m 16s) (220 74%) 2.6527\n",
      "6m 52s (- 1m 54s) (230 78%) 2.9266\n",
      "6m 59s (- 1m 34s) (240 81%) 2.7508\n",
      "7m 7s (- 1m 15s) (250 85%) 2.7018\n",
      "7m 14s (- 0m 56s) (260 88%) 2.7949\n",
      "7m 22s (- 0m 39s) (270 91%) 2.5503\n",
      "7m 29s (- 0m 22s) (280 95%) 2.7104\n",
      "7m 37s (- 0m 6s) (290 98%) 2.9137\n",
      "####### Finished epoch 2 of 10 ########\n",
      "7m 48s (- 221m 34s) (10 3%) 3.5114\n",
      "7m 55s (- 108m 34s) (20 6%) 3.0899\n",
      "8m 2s (- 70m 49s) (30 10%) 2.5571\n",
      "8m 10s (- 51m 54s) (40 13%) 2.7040\n",
      "8m 18s (- 40m 30s) (50 17%) 2.3411\n",
      "8m 25s (- 32m 51s) (60 20%) 2.2337\n",
      "8m 33s (- 27m 22s) (70 23%) 2.0650\n",
      "8m 40s (- 23m 13s) (80 27%) 2.5163\n",
      "8m 48s (- 19m 57s) (90 30%) 2.9907\n",
      "8m 55s (- 17m 19s) (100 34%) 2.4829\n",
      "9m 3s (- 15m 9s) (110 37%) 2.5360\n",
      "9m 14s (- 13m 23s) (120 40%) 2.4811\n",
      "9m 23s (- 11m 50s) (130 44%) 2.7578\n",
      "9m 31s (- 10m 28s) (140 47%) 2.6911\n",
      "9m 38s (- 9m 15s) (150 51%) 2.3007\n",
      "9m 45s (- 8m 10s) (160 54%) 2.5435\n",
      "9m 53s (- 7m 13s) (170 57%) 2.5562\n",
      "10m 1s (- 6m 20s) (180 61%) 2.2818\n",
      "10m 8s (- 5m 33s) (190 64%) 2.3324\n",
      "10m 16s (- 4m 49s) (200 68%) 2.4751\n",
      "10m 24s (- 4m 9s) (210 71%) 2.4058\n",
      "10m 33s (- 3m 33s) (220 74%) 2.3253\n",
      "10m 41s (- 2m 58s) (230 78%) 2.2485\n",
      "10m 49s (- 2m 26s) (240 81%) 2.2085\n",
      "10m 56s (- 1m 55s) (250 85%) 2.2733\n",
      "11m 4s (- 1m 26s) (260 88%) 2.1039\n",
      "11m 11s (- 0m 59s) (270 91%) 2.4844\n",
      "11m 19s (- 0m 33s) (280 95%) 2.3945\n",
      "11m 26s (- 0m 9s) (290 98%) 2.3101\n",
      "####### Finished epoch 3 of 10 ########\n",
      "11m 38s (- 330m 30s) (10 3%) 3.3819\n",
      "11m 45s (- 161m 10s) (20 6%) 2.0868\n",
      "11m 54s (- 104m 45s) (30 10%) 2.1646\n",
      "12m 2s (- 76m 29s) (40 13%) 1.7209\n",
      "12m 11s (- 59m 30s) (50 17%) 2.1456\n",
      "12m 20s (- 48m 7s) (60 20%) 2.1267\n",
      "12m 28s (- 39m 56s) (70 23%) 1.9096\n",
      "12m 37s (- 33m 46s) (80 27%) 2.2450\n",
      "12m 46s (- 28m 58s) (90 30%) 2.1597\n",
      "12m 54s (- 25m 3s) (100 34%) 2.0708\n",
      "13m 3s (- 21m 51s) (110 37%) 2.1382\n",
      "13m 21s (- 19m 21s) (120 40%) 2.2893\n",
      "13m 36s (- 17m 9s) (130 44%) 2.1039\n",
      "13m 45s (- 15m 8s) (140 47%) 1.9249\n",
      "13m 56s (- 13m 22s) (150 51%) 1.9442\n",
      "14m 4s (- 11m 47s) (160 54%) 1.8216\n",
      "14m 12s (- 10m 22s) (170 57%) 2.4027\n",
      "14m 21s (- 9m 5s) (180 61%) 2.0807\n",
      "14m 30s (- 7m 56s) (190 64%) 1.8797\n",
      "14m 39s (- 6m 53s) (200 68%) 2.0400\n",
      "14m 48s (- 5m 55s) (210 71%) 2.1066\n",
      "14m 56s (- 5m 1s) (220 74%) 2.0970\n",
      "15m 5s (- 4m 12s) (230 78%) 1.8791\n",
      "15m 14s (- 3m 25s) (240 81%) 2.1648\n",
      "15m 24s (- 2m 42s) (250 85%) 1.9300\n",
      "15m 32s (- 2m 1s) (260 88%) 1.8303\n",
      "15m 41s (- 1m 23s) (270 91%) 1.8172\n",
      "15m 50s (- 0m 47s) (280 95%) 2.1690\n",
      "16m 1s (- 0m 13s) (290 98%) 2.0618\n",
      "####### Finished epoch 4 of 10 ########\n",
      "16m 19s (- 463m 25s) (10 3%) 2.5194\n",
      "16m 31s (- 226m 18s) (20 6%) 2.1028\n",
      "16m 37s (- 146m 14s) (30 10%) 1.5717\n",
      "16m 41s (- 106m 1s) (40 13%) 1.8216\n",
      "16m 46s (- 81m 52s) (50 17%) 1.7175\n",
      "16m 51s (- 65m 44s) (60 20%) 1.7045\n",
      "17m 1s (- 54m 28s) (70 23%) 1.7482\n",
      "17m 15s (- 46m 11s) (80 27%) 1.6892\n",
      "17m 27s (- 39m 35s) (90 30%) 1.6800\n",
      "17m 39s (- 34m 15s) (100 34%) 1.5120\n",
      "17m 50s (- 29m 51s) (110 37%) 1.7222\n",
      "18m 1s (- 26m 8s) (120 40%) 1.9397\n",
      "18m 10s (- 22m 55s) (130 44%) 1.7939\n",
      "18m 19s (- 20m 9s) (140 47%) 1.7077\n",
      "18m 28s (- 17m 44s) (150 51%) 1.5154\n",
      "18m 37s (- 15m 35s) (160 54%) 1.7971\n",
      "18m 45s (- 13m 40s) (170 57%) 1.6724\n",
      "18m 54s (- 11m 58s) (180 61%) 1.7181\n",
      "19m 3s (- 10m 25s) (190 64%) 1.6223\n",
      "19m 11s (- 9m 1s) (200 68%) 1.7195\n",
      "19m 21s (- 7m 44s) (210 71%) 1.4706\n",
      "19m 27s (- 6m 32s) (220 74%) 1.6720\n",
      "19m 34s (- 5m 26s) (230 78%) 1.4769\n",
      "19m 41s (- 4m 25s) (240 81%) 1.4449\n",
      "19m 47s (- 3m 29s) (250 85%) 1.7981\n",
      "19m 54s (- 2m 36s) (260 88%) 1.5793\n",
      "20m 1s (- 1m 46s) (270 91%) 1.7460\n",
      "20m 7s (- 1m 0s) (280 95%) 1.7073\n",
      "20m 20s (- 0m 16s) (290 98%) 1.8276\n",
      "####### Finished epoch 5 of 10 ########\n",
      "20m 37s (- 585m 39s) (10 3%) 2.3659\n",
      "20m 47s (- 284m 55s) (20 6%) 1.3699\n",
      "20m 58s (- 184m 35s) (30 10%) 1.5470\n",
      "21m 9s (- 134m 18s) (40 13%) 1.7156\n",
      "21m 19s (- 104m 5s) (50 17%) 1.5860\n",
      "21m 30s (- 83m 52s) (60 20%) 1.4443\n",
      "21m 40s (- 69m 20s) (70 23%) 1.4092\n",
      "21m 48s (- 58m 20s) (80 27%) 1.5388\n",
      "21m 57s (- 49m 45s) (90 30%) 1.4530\n",
      "22m 7s (- 42m 55s) (100 34%) 1.5528\n",
      "22m 16s (- 37m 14s) (110 37%) 1.5082\n",
      "22m 24s (- 32m 30s) (120 40%) 1.7377\n",
      "22m 32s (- 28m 26s) (130 44%) 1.4317\n",
      "22m 40s (- 24m 56s) (140 47%) 1.6777\n",
      "22m 48s (- 21m 53s) (150 51%) 1.3796\n",
      "22m 55s (- 19m 12s) (160 54%) 1.4861\n",
      "23m 3s (- 16m 48s) (170 57%) 1.5292\n",
      "23m 10s (- 14m 40s) (180 61%) 1.5122\n",
      "23m 18s (- 12m 45s) (190 64%) 1.3801\n",
      "23m 27s (- 11m 1s) (200 68%) 1.4819\n",
      "23m 35s (- 9m 26s) (210 71%) 1.3679\n",
      "23m 43s (- 7m 58s) (220 74%) 1.4413\n",
      "23m 50s (- 6m 38s) (230 78%) 1.5372\n",
      "23m 58s (- 5m 23s) (240 81%) 1.5137\n",
      "24m 6s (- 4m 14s) (250 85%) 1.5602\n",
      "24m 13s (- 3m 10s) (260 88%) 1.2461\n",
      "24m 21s (- 2m 9s) (270 91%) 1.4455\n",
      "24m 28s (- 1m 13s) (280 95%) 1.4320\n",
      "24m 36s (- 0m 20s) (290 98%) 1.3628\n",
      "####### Finished epoch 6 of 10 ########\n",
      "24m 47s (- 704m 9s) (10 3%) 1.9762\n",
      "24m 55s (- 341m 25s) (20 6%) 1.3792\n",
      "25m 3s (- 220m 32s) (30 10%) 1.3781\n",
      "25m 11s (- 160m 0s) (40 13%) 1.2739\n",
      "25m 19s (- 123m 36s) (50 17%) 1.3427\n",
      "25m 27s (- 99m 18s) (60 20%) 1.3484\n",
      "25m 35s (- 81m 53s) (70 23%) 1.2471\n",
      "25m 42s (- 68m 47s) (80 27%) 1.3645\n",
      "25m 50s (- 58m 33s) (90 30%) 1.2905\n",
      "25m 57s (- 50m 21s) (100 34%) 1.1658\n",
      "26m 5s (- 43m 37s) (110 37%) 1.5793\n",
      "26m 12s (- 38m 0s) (120 40%) 1.2834\n",
      "26m 20s (- 33m 13s) (130 44%) 1.2640\n",
      "26m 27s (- 29m 6s) (140 47%) 1.1382\n",
      "26m 34s (- 25m 30s) (150 51%) 1.1323\n",
      "26m 41s (- 22m 21s) (160 54%) 1.2361\n",
      "26m 49s (- 19m 34s) (170 57%) 1.2201\n",
      "26m 57s (- 17m 4s) (180 61%) 1.2687\n",
      "27m 5s (- 14m 49s) (190 64%) 1.3850\n",
      "27m 12s (- 12m 47s) (200 68%) 1.1124\n",
      "27m 20s (- 10m 56s) (210 71%) 1.3445\n",
      "27m 27s (- 9m 14s) (220 74%) 1.4080\n",
      "27m 35s (- 7m 40s) (230 78%) 1.2624\n",
      "27m 42s (- 6m 14s) (240 81%) 1.1004\n",
      "27m 51s (- 4m 54s) (250 85%) 1.3358\n",
      "28m 0s (- 3m 39s) (260 88%) 1.1440\n",
      "28m 10s (- 2m 30s) (270 91%) 1.2166\n",
      "28m 23s (- 1m 25s) (280 95%) 1.2297\n",
      "28m 37s (- 0m 23s) (290 98%) 1.2907\n",
      "####### Finished epoch 7 of 10 ########\n",
      "28m 52s (- 819m 52s) (10 3%) 1.7627\n",
      "29m 5s (- 398m 37s) (20 6%) 1.2210\n",
      "29m 16s (- 257m 36s) (30 10%) 1.0893\n",
      "29m 26s (- 187m 0s) (40 13%) 1.1241\n",
      "29m 37s (- 144m 33s) (50 17%) 1.2572\n",
      "29m 47s (- 116m 9s) (60 20%) 0.9824\n",
      "29m 55s (- 95m 45s) (70 23%) 1.1665\n",
      "30m 5s (- 80m 30s) (80 27%) 1.0548\n",
      "30m 14s (- 68m 33s) (90 30%) 1.0560\n",
      "30m 24s (- 58m 58s) (100 34%) 1.1107\n",
      "30m 32s (- 51m 5s) (110 37%) 1.0212\n",
      "30m 41s (- 44m 30s) (120 40%) 1.1938\n",
      "30m 50s (- 38m 54s) (130 44%) 1.0243\n",
      "31m 0s (- 34m 6s) (140 47%) 1.1226\n",
      "31m 7s (- 29m 53s) (150 51%) 0.9767\n",
      "31m 15s (- 26m 10s) (160 54%) 1.1295\n",
      "31m 22s (- 22m 53s) (170 57%) 1.5580\n",
      "31m 29s (- 19m 56s) (180 61%) 1.1235\n",
      "31m 36s (- 17m 18s) (190 64%) 1.1519\n",
      "31m 43s (- 14m 54s) (200 68%) 0.9961\n",
      "31m 51s (- 12m 44s) (210 71%) 1.0423\n",
      "31m 58s (- 10m 45s) (220 74%) 1.0485\n",
      "32m 5s (- 8m 55s) (230 78%) 1.0697\n",
      "32m 12s (- 7m 14s) (240 81%) 1.1148\n",
      "32m 19s (- 5m 41s) (250 85%) 1.1063\n",
      "32m 26s (- 4m 14s) (260 88%) 1.0504\n",
      "32m 33s (- 2m 53s) (270 91%) 1.0671\n",
      "32m 40s (- 1m 38s) (280 95%) 1.0044\n",
      "32m 48s (- 0m 27s) (290 98%) 1.0721\n",
      "####### Finished epoch 8 of 10 ########\n",
      "32m 58s (- 936m 38s) (10 3%) 1.3340\n",
      "33m 6s (- 453m 30s) (20 6%) 0.9390\n",
      "33m 13s (- 292m 21s) (30 10%) 0.9384\n",
      "33m 20s (- 211m 45s) (40 13%) 1.0831\n",
      "33m 27s (- 163m 18s) (50 17%) 1.0998\n",
      "33m 36s (- 131m 2s) (60 20%) 0.9447\n",
      "33m 44s (- 107m 56s) (70 23%) 1.0951\n",
      "33m 51s (- 90m 35s) (80 27%) 0.8717\n",
      "33m 59s (- 77m 2s) (90 30%) 0.9063\n",
      "34m 7s (- 66m 12s) (100 34%) 0.8818\n",
      "34m 14s (- 57m 17s) (110 37%) 1.0526\n",
      "34m 21s (- 49m 49s) (120 40%) 0.9227\n",
      "34m 29s (- 43m 30s) (130 44%) 0.9356\n",
      "34m 36s (- 38m 3s) (140 47%) 0.9420\n",
      "34m 43s (- 33m 19s) (150 51%) 0.9624\n",
      "34m 50s (- 29m 10s) (160 54%) 1.1210\n",
      "34m 57s (- 25m 29s) (170 57%) 0.9763\n",
      "35m 4s (- 22m 12s) (180 61%) 0.9810\n",
      "35m 11s (- 19m 15s) (190 64%) 1.0274\n",
      "35m 18s (- 16m 35s) (200 68%) 0.9232\n",
      "35m 25s (- 14m 10s) (210 71%) 0.9607\n",
      "35m 32s (- 11m 57s) (220 74%) 0.9668\n",
      "35m 39s (- 9m 55s) (230 78%) 1.0376\n",
      "35m 46s (- 8m 2s) (240 81%) 0.8622\n",
      "35m 53s (- 6m 19s) (250 85%) 0.9486\n",
      "36m 0s (- 4m 42s) (260 88%) 0.8766\n",
      "36m 8s (- 3m 12s) (270 91%) 0.8726\n",
      "36m 15s (- 1m 48s) (280 95%) 0.7693\n",
      "36m 23s (- 0m 30s) (290 98%) 0.9201\n",
      "####### Finished epoch 9 of 10 ########\n",
      "36m 33s (- 1038m 14s) (10 3%) 1.3973\n",
      "36m 40s (- 502m 31s) (20 6%) 0.7834\n",
      "36m 48s (- 323m 50s) (30 10%) 0.8617\n",
      "36m 55s (- 234m 26s) (40 13%) 0.6446\n",
      "37m 2s (- 180m 45s) (50 17%) 0.7605\n",
      "37m 10s (- 145m 0s) (60 20%) 0.9073\n",
      "37m 17s (- 119m 21s) (70 23%) 0.7643\n",
      "37m 25s (- 100m 5s) (80 27%) 0.8647\n",
      "37m 32s (- 85m 4s) (90 30%) 0.7399\n",
      "37m 39s (- 73m 2s) (100 34%) 0.9154\n",
      "37m 46s (- 63m 11s) (110 37%) 0.7811\n",
      "37m 53s (- 54m 56s) (120 40%) 0.9753\n",
      "38m 0s (- 47m 56s) (130 44%) 0.7894\n",
      "38m 7s (- 41m 56s) (140 47%) 0.8809\n",
      "38m 14s (- 36m 42s) (150 51%) 0.7907\n",
      "38m 22s (- 32m 7s) (160 54%) 0.9370\n",
      "38m 29s (- 28m 4s) (170 57%) 0.9463\n",
      "38m 36s (- 24m 27s) (180 61%) 0.6914\n",
      "38m 43s (- 21m 11s) (190 64%) 0.8061\n",
      "38m 50s (- 18m 15s) (200 68%) 0.8337\n",
      "38m 58s (- 15m 35s) (210 71%) 0.8025\n",
      "39m 5s (- 13m 8s) (220 74%) 0.7203\n",
      "39m 12s (- 10m 54s) (230 78%) 1.0243\n",
      "39m 19s (- 8m 50s) (240 81%) 0.8315\n",
      "39m 27s (- 6m 56s) (250 85%) 0.7392\n",
      "39m 34s (- 5m 10s) (260 88%) 0.8672\n",
      "39m 41s (- 3m 31s) (270 91%) 0.9153\n",
      "39m 48s (- 1m 59s) (280 95%) 0.8604\n",
      "39m 55s (- 0m 33s) (290 98%) 0.7279\n",
      "####### Finished epoch 10 of 10 ########\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(args['hidden_size_encoder'], input_lang.n_words, args['batch_size'], num_layers=args['num_layer_encoder'], bidirectional=args['bidirectional']).to(device)\n",
    "bridge = Linear(args['bidirectional'], args['hidden_size_encoder'], args['hidden_size_decoder']).to(device)\n",
    "decoder1 = DecoderRNN(args['hidden_size_decoder'], output_lang.n_words, args['batch_size'], num_layers=args['num_layer_decoder']).to(device)\n",
    "\n",
    "train_iters(encoder1, decoder1, bridge, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  i m strong  EOS\n",
      "Output:  i m strong  EOS\n",
      "Predicted Output:  i m strong  <EOS>\n",
      "\n",
      "Input:  i m a patient  EOS\n",
      "Output:  i m a patient  EOS\n",
      "Predicted Output:  i m a patient  <EOS>\n",
      "\n",
      "Input:  you re a wonderful guy  EOS\n",
      "Output:  you re a wonderful guy  EOS\n",
      "Predicted Output:  you re a wonderful guy  <EOS>\n",
      "\n",
      "Input:  she is a doctor  EOS\n",
      "Output:  she is a doctor  EOS\n",
      "Predicted Output:  she is a doctor  <EOS>\n",
      "\n",
      "Input:  i m not eating this  EOS\n",
      "Output:  i m not eating this  EOS\n",
      "Predicted Output:  i m not eating this  <EOS>\n",
      "\n",
      "Input:  he is totally dependent on his parents  EOS\n",
      "Output:  he is totally dependent on his parents  EOS\n",
      "Predicted Output:  he is always on on his parents  <EOS>\n",
      "\n",
      "Input:  you re lucky that you have a job  EOS\n",
      "Output:  you re lucky that you have a job  EOS\n",
      "Predicted Output:  you re lucky that you have a job  <EOS>\n",
      "\n",
      "Input:  you re very lonely  EOS\n",
      "Output:  you re very lonely  EOS\n",
      "Predicted Output:  you re very lonely  <EOS>\n",
      "\n",
      "Input:  i m about ready  EOS\n",
      "Output:  i m about ready  EOS\n",
      "Predicted Output:  i m ready ready  <EOS>\n",
      "\n",
      "Input:  she studies mathematics  EOS\n",
      "Output:  she studies mathematics  EOS\n",
      "Predicted Output:  she spoke bad  <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformations import sentence_from_tensor\n",
    "\n",
    "def evaluate(encoder, decoder, bridge, input_tensor, max_length=args['MAX_LENGTH']):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        if args['bidirectional']:\n",
    "            encoder_outputs = torch.zeros(args['batch_size'], max_length, 2 * encoder['hidden_size'], device=device)\n",
    "            encoder_hidden_forward = encoder_hidden['forward']\n",
    "            encoder_hidden_backward = encoder_hidden['backward']\n",
    "\n",
    "            for ei in range(input_length):\n",
    "                (encoder_hidden_forward, encoder_hidden_backward) = encoder(\n",
    "                    (input_tensor[ei],input_tensor[input_length - 1 - ei]), (encoder_hidden_forward,encoder_hidden_backward))\n",
    "\n",
    "            hn_forward, cn_forward = encoder_hidden_forward\n",
    "            hn_backward, cn_backward = encoder_hidden_backward\n",
    "\n",
    "            encoder_hn = torch.cat((hn_forward, hn_backward), 2)\n",
    "            encoder_cn = torch.cat((cn_forward, cn_backward), 2)\n",
    "\n",
    "            encoder_hn_last_layer = encoder_hn[-1].view(1, 1, -1)\n",
    "            encoder_cn_last_layer = encoder_cn[-1].view(1,1,-1)\n",
    "\n",
    "            encoder_hidden_last = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        else:\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(\n",
    "                    input_tensor[ei], encoder_hidden)\n",
    "\n",
    "            hn, cn = encoder_hidden\n",
    "            encoder_hn_last_layer = hn[-1].view(1,1,-1)\n",
    "            encoder_cn_last_layer = cn[-1].view(1,1,-1)\n",
    "            encoder_hidden_last = [encoder_hn_last_layer, encoder_cn_last_layer]\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)\n",
    "        encoder_hidden_last = [bridge(item) for item in encoder_hidden_last]\n",
    "        decoder_hidden = encoder_hidden_last\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "def evaluate_randomly(encoder, decoder, bridge, n=10):\n",
    "    for i in range(n):\n",
    "        pair = testset[i]['sentence']\n",
    "        input_tensor, mask_input = reformat_tensor_mask(pair[:,0,:].view(1,1,-1))\n",
    "        input_tensor = input_tensor[input_tensor != 0]\n",
    "        output_tensor, mask_output = reformat_tensor_mask(pair[:,1,:].view(1,1,-1))\n",
    "        output_tensor = output_tensor[output_tensor != 0]\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            input_tensor = input_tensor.cuda()\n",
    "            output_tensor = output_tensor.cuda()\n",
    "\n",
    "        input_sentence = ' '.join(sentence_from_tensor(input_lang, input_tensor))\n",
    "        output_sentence = ' '.join(sentence_from_tensor(output_lang, output_tensor))\n",
    "        print('Input: ', input_sentence)\n",
    "        print('Output: ', output_sentence)\n",
    "        output_words = evaluate(encoder, decoder, bridge, input_tensor)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('Predicted Output: ', output_sentence)\n",
    "        print('')\n",
    "\n",
    "evaluate_randomly(encoder1, decoder1, bridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
