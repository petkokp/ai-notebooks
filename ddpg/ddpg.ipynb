{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Continuous control with deep reinforcement learning\" paper implementation - http://arxiv.org/pdf/1509.02971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from agent import Agent\n",
    "import imageio\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "np.random.seed(0)\n",
    "\n",
    "agent = Agent(lr_actor=0.000025, lr_critic=0.00025, input_dims=[8], tau=0.001, batch_size=64,\n",
    "              layer1_size=400, layer2_size=300, n_actions=2)\n",
    "\n",
    "score_history = []\n",
    "record = False\n",
    "img_path = 'images'\n",
    "if not os.path.exists(img_path):\n",
    "    pathlib.Path(img_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    done = False\n",
    "    score = 0\n",
    "    obs = env.reset()\n",
    "    frame_set = []\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        record = True\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        act = agent.choose_action(obs)\n",
    "        next_state, reward, truncated, done, info = env.step(act)\n",
    "        agent.memory.push(obs, act, reward, next_state, int(done))\n",
    "        agent.learn()\n",
    "        score += reward\n",
    "\n",
    "        if record:\n",
    "            frame_set.append(env.render())\n",
    "        obs = next_state\n",
    "    \n",
    "    if record:\n",
    "        imageio.mimsave(os.path.join(img_path, f'eps-{i}.gif'), frame_set, fps=30)\n",
    "        record = False   \n",
    "    score_history.append(score)\n",
    "\n",
    "    print(\"==============================\")\n",
    "    print('Episode: ', i)\n",
    "    print('Score: ', score)\n",
    "    print('Last 100 avg: ', np.mean(score_history[-100:]))\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        agent.save_models()\n",
    "        plt.plot(score_history)\n",
    "        plt.xlabel('episodes')\n",
    "        plt.ylabel('score')\n",
    "        plt.grid()\n",
    "        plt.savefig(os.path.join(img_path, \"score_fig.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f94c6b32fbda5dcd64daf382f382d2d5da78e483f351d87e126340144fcf47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
